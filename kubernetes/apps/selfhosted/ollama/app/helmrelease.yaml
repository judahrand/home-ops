---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s-labs/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app ollama
  namespace: selfhosted
spec:
  interval: 1h
  chartRef:
    kind: OCIRepository
    name: app-template
  install:
    remediation:
      retries: -1
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  values:

    controllers:
      main:
        type: deployment
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          main:
            image:
              repository: docker.io/ollama/ollama
              tag: 0.7.0-rocm
            env:
              TZ: Europe/London
              # LIBVA_DRIVER_NAME: i965
              OLLAMA_HOST: 0.0.0.0
              OLLAMA_ORIGINS: "*"
              OLLAMA_MODELS: &modelPath /models
              HSA_OVERRIDE_GFX_VERSION: "11.0.2"
            # securityContext:
            #   privileged: true
            resources:
              requests:
                cpu: 200m
                memory: 4Gi
              limits:
                memory: 24Gi
                amd.com/gpu: 1
                # gpu.intel.com/i915: "1"

    service:
      main:
        controller: main
        ports:
          http:
            port: &port 11434

    persistence:
      config:
        existingClaim: ollama
        globalMounts:
          - path: /root/.ollama
      models:
        storageClass: openebs-hostpath
        accessMode: ReadWriteOnce
        size: 50Gi
        globalMounts:
          - path: *modelPath
